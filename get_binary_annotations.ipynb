{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "output = torch.randn([16,1]).random_(2)\n",
    "target = torch.empty([16,14]).random_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31.2500)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss(output, target[:,2].reshape([16,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.nn' from '/home/roberto/Documents/NIH_ChestXRay/.env/lib/python3.8/site-packages/torch/nn/__init__.py'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Atelectasis', 7996)\n",
      "('Cardiomegaly', 1950)\n",
      "('Effusion', 9261)\n",
      "('Infiltration', 13914)\n",
      "('Mass', 3988)\n",
      "('Nodule', 4375)\n",
      "('Pneumonia', 978)\n",
      "('Pneumothorax', 3705)\n",
      "('Consolidation', 3263)\n",
      "('Edema', 1690)\n",
      "('Emphysema', 1799)\n",
      "('Fibrosis', 1158)\n",
      "('Pleural_Thickening', 2279)\n",
      "('Hernia', 144)\n"
     ]
    }
   ],
   "source": [
    "labels_names = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "for pair in zip([ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'],labels.sum(axis=0)):\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOSEN CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE LABELS FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_label(label_n, filename, output_type):\n",
    "    with open(filename, 'r') as file:\n",
    "        data_labels = file.read()\n",
    "        data_labels = data_labels.split('\\n')\n",
    "        images_names = [entry.split(' ')[0] for entry in data_labels]\n",
    "        labels = [[int(p) for p in entry.split(' ')[1:]] for entry in data_labels if len(entry) > 10]\n",
    "        labels = np.array(labels)\n",
    "        images_names = np.array(images_names)\n",
    "\n",
    "        if images_names[-1]=='':\n",
    "            images_names = images_names[:-1]\n",
    "\n",
    "        print(labels[labels[:,2]==1].shape)\n",
    "\n",
    "        print(labels[labels.sum(axis=1)==0].shape)\n",
    "\n",
    "        labels_class = labels[ (labels[:,class_n]==1) | (labels.sum(axis=1)==0)]\n",
    "        images_class = images_names[ (labels[:,class_n]==1) | (labels.sum(axis=1)==0)]\n",
    "\n",
    "        data = ''\n",
    "        for image, label in zip(images_class, labels_class):\n",
    "            data += image + ' ' + ' '.join([str(p) for p in label])\n",
    "            data += '\\n'\n",
    "\n",
    "\n",
    "        os.makedirs(f'./labels/binary_{labels_names[class_n]}', exist_ok=True)\n",
    "        with open(f'./labels/binary_{labels_names[class_n]}/{output_type}.txt','w') as file:\n",
    "            file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9261, 14)\n",
      "(42405, 14)\n",
      "(1292, 14)\n",
      "(6079, 14)\n",
      "(2754, 14)\n",
      "(11928, 14)\n"
     ]
    }
   ],
   "source": [
    "choose_label(2, './labels/train_list.txt', 'train')\n",
    "choose_label(2, './labels/val_list.txt', 'valid')\n",
    "choose_label(2, './labels/test_list.txt', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1684, 14)\n",
      "(8649, 14)\n"
     ]
    }
   ],
   "source": [
    "filename = './labels/binary_Effusion/train20%.txt'\n",
    "with open(filename, 'r') as file:\n",
    "    data_labels = file.read()\n",
    "    data_labels = data_labels.split('\\n')\n",
    "    images_names = [entry.split(' ')[0] for entry in data_labels]\n",
    "    labels = [[int(p) for p in entry.split(' ')[1:]] for entry in data_labels if len(entry) > 10]\n",
    "    labels = np.array(labels)\n",
    "    images_names = np.array(images_names)\n",
    "\n",
    "    if images_names[-1]=='':\n",
    "        images_names = images_names[:-1]\n",
    "\n",
    "    print(labels[labels[:,2]==1].shape)\n",
    "\n",
    "    print(labels[labels.sum(axis=1)==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7577, 14)\n",
      "(33756, 14)\n"
     ]
    }
   ],
   "source": [
    "filename = './labels/binary_Effusion/train80%.txt'\n",
    "with open(filename, 'r') as file:\n",
    "    data_labels = file.read()\n",
    "    data_labels = data_labels.split('\\n')\n",
    "    images_names = [entry.split(' ')[0] for entry in data_labels]\n",
    "    labels = [[int(p) for p in entry.split(' ')[1:]] for entry in data_labels if len(entry) > 10]\n",
    "    labels = np.array(labels)\n",
    "    images_names = np.array(images_names)\n",
    "\n",
    "    if images_names[-1]=='':\n",
    "        images_names = images_names[:-1]\n",
    "\n",
    "    print(labels[labels[:,2]==1].shape)\n",
    "\n",
    "    print(labels[labels.sum(axis=1)==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.493333333333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33.7/7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.374999999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.6/1.6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
