{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - treinar apenas como classificacao binaria no caso de psudo labels? nothing vs all\n",
    "   - Aumentar o LR quando realizando o finetuning nos 10%?\n",
    "   - cyclic lr no treinamento pseudolabels\n",
    "   - usar a partica treino/este do chexnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento apenas com labels confiantes\n",
    "    desconsiderar a perda em labels fora das faixas proximas de 0 e 1\n",
    "    \n",
    "- Escolhendo as melhores e piores pseudolabels para realizar o pre-treinamento\n",
    "- Garantindo a mesma proporcao de labels presente no conjunto anotado\n",
    "- A funcao de perda BCE desconsiderando as labels fora destas faixas\n",
    "    - [1 0 1 0 -1 -1 -1] resulta em uma mascara que remove a perda nas labels -1\n",
    "    \n",
    "- Vemos que o desempenho da rede estudante nao ultrapassa o teacher\n",
    "- O treinamento do finetuning com as imagens classificadas inicia melhor, como se os pseudo-labels funcionassem como um transfer-learning\n",
    "- Porem o desempenho nao melhora apos a primeira epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Experimentos\n",
    "    - mantendo a mesma proporcao de labels como no conjunto original\n",
    "    - diminuindo a proporcao e mantendo apenas labels com maior confianca\n",
    "    \n",
    "- O primeiro caso obteve um modelo baseado nas pseudolabels melhor, porem o finetuning ficou pior. Avaliar o porque\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "     - anotar o auroc durante o treinamento, mesmo para as pseudoplabels\n",
    "     - realizar o finetuning com uma taxa de aprendizado mais baixa\n",
    "     - testar mais data augmentation\n",
    "     - utilizar os pseudolabels durante o treinamento [?] nao esta no artigo original mas existe em outros metodos\n",
    "     \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOS\n",
    "    \n",
    "- treinamento com apenas um label\n",
    "    - diminuir o dataset para uma classe\n",
    "    - escolhendo uma label vs outros labels\n",
    "    - label/outros ou labels/normal/nao-normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for making the intermediate predictions\n",
    " - using the 10% supervised models, we create the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best 10% predictions for each label, for the unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./runs/effusion_train05%_teacher_00/pseudo_labels95.txt', 'r') as file:\n",
    "    data_preds = file.read()\n",
    "    data_preds = data_preds.split('\\n')\n",
    "\n",
    "    images_names_pseudo = [entry.split(' ')[0] for entry in data_preds if len(entry) > 10]\n",
    "    preds = [[float(p)  for p in entry.split(' ')[1:-1]]  for entry in data_preds if len(entry) > 10]\n",
    "    preds = np.array(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./labels/binary_Effusion/train05%.txt', 'r') as file:\n",
    "    data_labels = file.read()\n",
    "    data_labels = data_labels.split('\\n')\n",
    "    images_names_finetune = [entry.split(' ')[0] for entry in data_labels]\n",
    "    labels = [[int(p) for p in entry.split(' ')[1:]] for entry in data_labels if len(entry) > 10]\n",
    "    labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio betwen label 1 (effusion) and label 0 (normal) is 0.15614103060829135\n"
     ]
    }
   ],
   "source": [
    "effusion_labels = labels[:,2]\n",
    "effusion_ratio = np.sum(effusion_labels)/effusion_labels.shape[0]\n",
    "print(f\"The ratio betwen label 1 (effusion) and label 0 (normal) is {effusion_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a total of 49085 predicitons, we are taking : \n",
      " -- Getting 3832   [7.81% of total] high predictions\n",
      " -- Getting 20710  [42.19% of total]low predictions\n"
     ]
    }
   ],
   "source": [
    "filtered_preds = -1*np.ones([preds.shape[0], 14]) # Start ignoring all entries\n",
    "\n",
    "k_best = 0.5 #Use the k_best% best low and high predictioins\n",
    "k_high_predictions = int(k_best*effusion_ratio*preds.shape[0])\n",
    "k_low_predictions = int(k_best*(1-effusion_ratio)*preds.shape[0])\n",
    "\n",
    "print(f\"From a total of {preds.shape[0]} predicitons, we are taking : \")\n",
    "print(f\" -- Getting {k_high_predictions}   [{round(100*k_high_predictions/preds.shape[0],2)}% of total] high predictions\")\n",
    "print(f\" -- Getting {k_low_predictions}  [{round(100*k_low_predictions/preds.shape[0],2)}% of total]low predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability limits are:\n",
      " -- 0.8495872616767883 for label 1\n",
      " -- 0.005060830619186163 for label 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_preds = preds[:, 0]\n",
    "n_argsorted = np.argsort(n_preds)\n",
    "k_highprob = n_preds[n_argsorted[-k_high_predictions]] # the lower bound of probability to be included in the ssl training\n",
    "k_lowprob = n_preds[n_argsorted[k_low_predictions]] # the lower bound of probability to be included in the ssl training\n",
    "print(f\"The probability limits are:\")\n",
    "print(f\" -- {k_highprob} for label 1\")\n",
    "print(f\" -- {k_lowprob} for label 0\")\n",
    "\n",
    "\n",
    "filtered_preds[preds[:,0] >= k_highprob, 2] = 1\n",
    "filtered_preds[preds[:,0] <= k_lowprob, 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''\n",
    "for image, filtered_pred in zip(images_names_pseudo, filtered_preds.astype(np.int8)):\n",
    "    if filtered_pred[2]==-1:\n",
    "        continue\n",
    "    data += image + ' ' + ' '.join([str(p) for p in filtered_pred])\n",
    "    data += '\\n'\n",
    "    \n",
    "with open('./runs/effusion_train05%_teacher_00/pseudo_labels95_filtered.txt', 'w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options 3 - ignore uncertain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.functional.binary_cross_entropy_with_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False]])\n",
      "tensor(2.7601)\n"
     ]
    }
   ],
   "source": [
    "target = torch.FloatTensor([[ 0.,  0., 1.,  1.,  -1.,  -1.],\n",
    "                            [ 0.,  0., 1.,  1.,  -1.,  -1.]])\n",
    "\n",
    "output = torch.FloatTensor([[0.4037, 0.5437, 0.5194, 0.7067, 0.3060, 0.4174],\n",
    "                            [0.3490, 0.5077, 0.4751, 0.7386, 0.3352, 0.4569]])\n",
    "\n",
    "loss_weight = torch.gt(target, -0.5)\n",
    "loss = criterion(output, target, loss_weight)\n",
    "\n",
    "print(loss_weight)\n",
    "print(loss*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "tensor(2.7601)\n"
     ]
    }
   ],
   "source": [
    "target = torch.FloatTensor([[ 0.,  0., 1.,  1.],\n",
    "                            [ 0.,  0., 1.,  1.]])\n",
    "\n",
    "output = torch.FloatTensor([[0.4037, 0.5437, 0.5194, 0.7067 ],\n",
    "                            [0.3490, 0.5077, 0.4751, 0.7386]])\n",
    "\n",
    "loss_weight = torch.gt(target, -0.5)\n",
    "loss = criterion(output, target, loss_weight)\n",
    "\n",
    "print(loss_weight)\n",
    "print(loss*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1 - keep proportion of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = preds.shape[0]\n",
    "for L in range(14):\n",
    "    pseudolabels = np.sort(preds[:, L], )\n",
    "    min_prob = pseudolabels[N-int(N*label_ratios[L])-1]\n",
    "    preds[:, L] = 1.0*(preds[:, L] >min_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2 - keep those above mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 1.0*(preds >preds.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list90_pseudo = []\n",
    "for pair in zip(images_names, preds):\n",
    "    pred = f\"{pair[0]} {' '.join([str(int(p)) for p in pair[1]])}\"\n",
    "    train_list90_pseudo.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./labels/train_list90_pseudo2.txt', 'w') as file:\n",
    "    for pred in train_list90_pseudo:\n",
    "        file.write(pred+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0.07252079248428345'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-63110627475d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                  [0.229, 0.224, 0.225])\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m train_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                 \u001b[0mimage_list_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_IMAGE_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                 transform=transforms.Compose([\n",
      "\u001b[0;32m~/Documents/CheXNet/read_data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, image_list_file, transform, return_image_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mimage_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mimage_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CheXNet/read_data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mimage_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mimage_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0.07252079248428345'"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "The main CheXNet model implementation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from read_data import ChestXrayDataSet\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "import progressbar\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from model import Resnet50, DenseNet121\n",
    "import time\n",
    "import json\n",
    "\n",
    "CKPT_PATH = './snapshots/model.pth.tar'\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "DATA_DIR = '/media/roberto/external/Data/images/images'\n",
    "TRAIN_IMAGE_LIST = './densenet_supervised10%_training/train_list90%_pseudolabels.txt'\n",
    "VAL_IMAGE_LIST = './labels/val_list.txt'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=TRAIN_IMAGE_LIST,\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.Resize(256),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomRotation(15),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                         [0.229, 0.224, 0.225])\n",
    "                                ]))\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "\n",
    "val_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(256),\n",
    "                                   transforms.TenCrop(224),\n",
    "                                   transforms.Lambda\n",
    "                                   (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                                   transforms.Lambda\n",
    "                                   (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                               ]))\n",
    "\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, target in val_loader:\n",
    "    a = img\n",
    "    b = target\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([str(p) for p in b[0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00021321_013.png'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/media/roberto/external/Data/images/images/00021321_013.png\".split(\"/\")[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSL",
   "language": "python",
   "name": "ssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
